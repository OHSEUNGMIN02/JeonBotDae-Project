# -*- coding: utf-8 -*-
"""Homework0726

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WCXzOguP8wqbUSc3VABEzYHZAljV3vqC
"""

# ---------------------------------------------
# [1] 설치
# ---------------------------------------------
!pip install -q pytube ultralytics norfair opencv-python-headless

# ---------------------------------------------
# [2] 유튜브 영상 다운로드
# ---------------------------------------------
from google.colab import files

# 업로드 창이 열립니다. 다운로드한 MP4 파일을 선택하세요.
uploaded = files.upload()
import shutil

# 업로드한 파일 중 첫 번째 파일을 가져와 복사합니다.
filename = list(uploaded.keys())[0]
shutil.copy(filename, "output_tracked.mp4")
print(f" '{filename}' → 'output_tracked.mp4'로 복사 완료")

import os, cv2, math, logging
import numpy as np
from ultralytics import YOLO
from norfair import Detection, Tracker, draw_tracked_objects

log_path = "collision_log.txt"
frame_output_dir = "collision_frames"

logging.basicConfig(
    filename=log_path,
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    force=True
)

model = YOLO("yolov8n.pt")
tracker = Tracker(distance_function="euclidean", distance_threshold=50)

def predict_collision(positions, speeds, threshold=9999):
    ids = list(positions.keys())
    warnings = []
    for i in range(len(ids)):
        for j in range(i + 1, len(ids)):
            id1, id2 = ids[i], ids[j]
            if id1 not in speeds or id2 not in speeds:
                continue
            pos1, pos2 = positions[id1], positions[id2]
            speed1, speed2 = speeds[id1], speeds[id2]
            dist = math.dist(pos1, pos2)
            rel_speed = abs(speed1 - speed2)
            if rel_speed < 1e-3: continue
            collision_time = dist / rel_speed
            if collision_time < threshold:
                logging.warning(f"Collision Warning: ID {id1} and {id2} | Time: {collision_time:.2f}s")
                warnings.append((id1, id2))
    return warnings

cap = cv2.VideoCapture("output_tracked.mp4")
fps = cap.get(cv2.CAP_PROP_FPS)
if fps == 0: fps = 30
frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
out = cv2.VideoWriter("tracked_output.mp4", cv2.VideoWriter_fourcc(*'mp4v'), fps, frame_size)

positions, prev_positions, speeds = {}, {}, {}
frame_count = 0
MAX_FRAMES = 2000
MAX_TRACKED_OBJECTS = 100

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print(" 영상 끝났거나 오류 발생")
        break
    frame_count += 1
    if frame_count > MAX_FRAMES:
        break

    results = model(frame, verbose=False)[0]
    detections = []
    for box in results.boxes.data:
        x1, y1, x2, y2, conf, cls = box.cpu().numpy()
        if int(cls) in [2, 3, 5, 7]:
            cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
            detections.append(Detection(points=np.array([cx, cy]), scores=np.array([conf])))

    tracked_objects = tracker.update(detections=detections)
    if len(tracked_objects) > MAX_TRACKED_OBJECTS:
        continue

    for obj in tracked_objects:
        obj_id = obj.id
        x, y = obj.estimate[0]
        positions[obj_id] = (x, y)
        if obj_id in prev_positions:
            dist = math.dist((x, y), prev_positions[obj_id])
            speeds[obj_id] = dist * fps
        prev_positions[obj_id] = (x, y)

    warning_pairs = predict_collision(positions, speeds)
    warning_ids = set([vid for pair in warning_pairs for vid in pair])

    for obj in tracked_objects:
        obj_id = obj.id
        cx, cy = map(int, obj.estimate[0])
        color = (0, 0, 255) if obj_id in warning_ids else (0, 255, 0)
        cv2.circle(frame, (cx, cy), 6, color, -1)
        cv2.putText(frame, f"ID {obj_id}", (cx + 5, cy - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
    draw_tracked_objects(frame, tracked_objects)
    out.write(frame)

cap.release()
out.release()
print(" 차량 추적 완료 → 'tracked_output.mp4' 생성됨")

def extract_warning_frames(video_path, log_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    with open(log_path, 'r') as f:
        lines = f.readlines()
    warning_times = []
    for line in lines:
        if "Collision Warning" in line:
            try:
                time_str = line.split("Time:")[1].split("s")[0].strip()
                warning_times.append(float(time_str))
            except: continue
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    saved_count = 0
    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        current_time = frame_idx / fps
        for warn_time in warning_times:
            if abs(current_time - warn_time) < 0.5:
                filename = os.path.join(output_folder, f"warning_frame_{frame_idx}.jpg")
                cv2.imwrite(filename, frame)
                saved_count += 1
                break
        frame_idx += 1
    cap.release()
    print(f" {saved_count}장의 충돌 프레임 저장 완료 → '{output_folder}'")

extract_warning_frames("tracked_output.mp4", log_path, frame_output_dir)

files.download("tracked_output.mp4")